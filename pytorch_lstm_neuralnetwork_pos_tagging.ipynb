{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==0.4.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.2.1\n",
      "device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torchtext\n",
    "import sys\n",
    "!{sys.executable} -m pip freeze| grep torch\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re, os.path\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print('device={}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformar base CETEN para TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 537 µs, sys: 0 ns, total: 537 µs\n",
      "Wall time: 621 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels = ['N', 'PROP', 'ADJ','V', 'PERS', 'DET', 'SPEC', 'ADV', 'NUM', 'PRP', 'IN', 'KS', 'KC', 'EC']\n",
    "text_tag_re = re.compile(r'^(.+?)\\s.*?\\s(' + '|'.join(labels) + ')\\s')\n",
    "CETEN_path = 'resource/CETENFolha-1.0_jan2014.cg'\n",
    "train_path = 'resource/CETENFolha-1.0_jan2014.cg.tsv'\n",
    "def build_sentence(sentence_lines):\n",
    "    text = []\n",
    "    labels = []\n",
    "    for sentence_line in sentence_lines:\n",
    "        for match in text_tag_re.finditer(sentence_line):\n",
    "            text.append(match.groups()[0])\n",
    "            labels.append(match.groups()[1])\n",
    "    return text, labels\n",
    "\n",
    "def sentence_lines_iterator(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        sentence_lines = []\n",
    "        for line in f:\n",
    "            if line.startswith('</s>'):\n",
    "                text, labels = build_sentence(sentence_lines)\n",
    "                if len(text) > 0:\n",
    "                    yield text, labels\n",
    "                sentence_lines = []\n",
    "            else:\n",
    "                sentence_lines.append(line)            \n",
    "        f.close()\n",
    "\n",
    "def persist_tsv(filename_from, filename_to):\n",
    "    if os.path.isfile(filename_to):\n",
    "        return\n",
    "    with open(filename_to, 'w+') as fw:\n",
    "        fw.write('text\\tlabel\\n')\n",
    "        for text, labels in sentence_lines_iterator(filename_from):\n",
    "            text_col = ' '.join(text)\n",
    "            label_col = ' '.join(labels)\n",
    "            fw.write(text_col + '\\t' + label_col + '\\n')\n",
    "        fw.close()\n",
    "persist_tsv(CETEN_path, train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar e dividir em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 ms, sys: 606 µs, total: 1.95 ms\n",
      "Wall time: 1.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "txt_field = torchtext.data.Field(sequential=True, \n",
    "                       include_lengths=True, \n",
    "                       use_vocab=True)\n",
    "label_field = torchtext.data.Field(sequential=True, \n",
    "                         use_vocab=False)\n",
    "train_val_fields = [\n",
    "    ('text', txt_field),\n",
    "    ('label', label_field)\n",
    "]\n",
    "trainds = torchtext.data.TabularDataset(path=train_path, \n",
    "                                            format='tsv',\n",
    "                                            fields=train_val_fields, \n",
    "                                            skip_header=True)\n",
    "# TODO Encontrar um jeito rápido de fazer shuffle e depois split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.15 ms, sys: 79 µs, total: 4.23 ms\n",
      "Wall time: 4.15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "txt_field.build_vocab(trainds, max_size=500000)\n",
    "label_field.build_vocab(trainds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 778\n",
      "número de classes: 14\n",
      "<unk> 0\n",
      "<pad> 1\n",
      "de 2\n",
      "o 3\n",
      "a 4\n",
      "em 5\n",
      "que 6\n",
      "e 7\n",
      "os 8\n",
      "para 9\n"
     ]
    }
   ],
   "source": [
    "print('Tamanho do vocabulário:', len(txt_field.vocab))\n",
    "print('número de classes:', len(label_field.vocab))\n",
    "for i, word in enumerate(txt_field.vocab.itos[:10]):\n",
    "    print(word, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT 25\n",
      "em 5\n",
      "o 3\n",
      "governo 21\n"
     ]
    }
   ],
   "source": [
    "for word in 'PT em o governo'.split(' '):\n",
    "    print(word, txt_field.vocab.stoi[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = trainds.split(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de dados de treinamento: 79\n",
      "número de dados de validação: 20\n"
     ]
    }
   ],
   "source": [
    "print('número de dados de treinamento:', len(train))\n",
    "print('número de dados de validação:', len(valid))\n",
    "#print('número de dados de teste:', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.74 ms, sys: 0 ns, total: 6.74 ms\n",
      "Wall time: 6.16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wv_path = 'resource/CETENFolha-1.0_jan2014.cg.wv'\n",
    "if not os.path.isfile(wv_path):\n",
    "    sentences = [x for x in trainds.text]\n",
    "    model = gensim.models.Word2Vec (sentences, size=150, window=10, workers=10, min_count=1)\n",
    "    model.train(sentences,total_examples=len(sentences),epochs=4)\n",
    "    model.wv.save(wv_path)\n",
    "    del model\n",
    "    del sentences\n",
    "wv = KeyedVectors.load(wv_path, mmap='r')\n",
    "label_to_ix = {label: i for i, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "tensor([[-1.0430,  1.5876,  1.1685,  0.6252, -0.3075]], grad_fn=<EmbeddingBackward>)\n",
      "tensor([[-1.0430,  1.5876,  1.1685,  0.6252, -0.3075]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# ignorar\n",
    "print(wv.index2word[0])\n",
    "#print(wv.vectors[0])\n",
    "#print(wv['de'] == wv.vectors[0])\n",
    "weights = torch.FloatTensor(wv.vectors)\n",
    "em = nn.Embedding.from_pretrained(weights)\n",
    "lookup_tensor = torch.tensor([0], dtype=torch.long)\n",
    "#print(em(['de'])[0])\n",
    "#print(wv.vectors[0])\n",
    "# txt_field.build_vocab(trainds, valds, max_size=len(wv.index2word), vectors=wv.vectors)\n",
    "\n",
    "#embedding = nn.Embedding.from_pretrained(weights)\n",
    "#label_field.build_vocab(trainds)\n",
    "#print(wv['A'])\n",
    "#my_iterator = [x for x in trainds.text]\n",
    "#print(my_iterator[0])\n",
    "#txt_field.build_vocab(trainds)\n",
    "#vectors = torchtext.vocab.Vectors(wv_path)\n",
    "#txt_field.vocab.set_vectors(vectors.stoi, vectors.vectors, vectors.dim)\n",
    "#embedding = nn.Embedding.from_pretrained(torch.FloatTensor(txt_field.vocab.vectors))\n",
    "\n",
    "\n",
    "#print(len(wv.index2word))\n",
    "#txt_field.build_vocab(trainds, max_size=len(wv.index2word), vectors=wv)\n",
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([0], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-237c094c736b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucketIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_iter = torchtext.data.BucketIterator(train, batch_size=batch_size, repeat=True)\n",
    "valid_iter = torchtext.data.BucketIterator(valid, batch_size=batch_size, repeat=False)\n",
    "#test_iter = torchtext.data.BucketIterator(valds, batch_size=len(valds), repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-617d3d700cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbi_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#batch = next(iter(train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbi_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch.text.shape = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch.text.type = {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m    200\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "#for batch in train_iter.__iter__():\n",
    "#bi = data.BucketIterator(trainds, batch_size=10, repeat=False)\n",
    "#print(dir(bi))\n",
    "bi_iter = iter(valid_iter)\n",
    "#batch = next(iter(train))\n",
    "for batch in bi_iter:\n",
    "    print(\"batch.text.shape = {}\".format(batch.text.shape))\n",
    "    print(\"batch.text.type = {}\\n\".format(batch.text.type()))\n",
    "    print(\"batch.label.shape = {}\".format(batch.label.shape))\n",
    "    print(\"batch.label.type = {}\\n\".format(batch.label.type()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        \n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "\n",
    "#input_dim = np.prod(train_dataset[0][0].size()) #(1, 28, 28)\n",
    "#input_dim = train_dataset[0][0].size()[1]\n",
    "input_dim = 150\n",
    "hidden_dim = batch_size\n",
    "layer_dim = 1\n",
    "output_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(iter, loss, elapsed_seconds):\n",
    "    correct = 0\n",
    "    total = 0    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, input_dim, input_dim).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += int((predicted.cpu() == labels.cpu()).sum())\n",
    "    accuracy = 100 * correct / total\n",
    "    iter_seconds = iter/elapsed_seconds\n",
    "    remaining_seconds = round((n_iters - iter)/iter_seconds)\n",
    "    perc_done = round(iter/n_iters * 100)\n",
    "    print('iteration={} of {} ({}%), loss={}, accuracy={}%, elapsed_seconds={}, remaning_seconds={}'.format(iter, n_iters, perc_done, round(loss.item(), 2), accuracy, elapsed_seconds, remaining_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(300, 100, batch_first=True)\n",
      "  (fc): Linear(in_features=100, out_features=16, bias=True)\n",
      ")\n",
      "6\n",
      "torch.Size([400, 300])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([16, 100])\n",
      "torch.Size([16])\n",
      "<torchtext.data.example.Example object at 0x7f14d24d8908>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0e316a6c9c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 5 # qtd vezes que treinará sobre todo o dataset\n",
    "n_iters = int(len(train) / batch_size * num_epochs)\n",
    "\n",
    "iter = 0\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    loss = None\n",
    "    for i, batch in enumerate(train):\n",
    "        print(batch)\n",
    "        images = batch.text.view(-1, input_dim, input_dim).requires_grad_().to(device)\n",
    "        labels = batch.label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter += 1\n",
    "        if iter % 500 == 0:\n",
    "            calculate_accuracy(iter, loss, round(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
